# ABOUTME: Just command runner for common nuPlan development tasks
# ABOUTME: Run `just` or `just --list` to see all available commands

# Default recipe - show help
default:
    @just --list

# Setup full development environment with CUDA support
setup:
    @echo "ğŸ“¦ Setting up nuPlan development environment with CUDA..."
    uv sync --all-extras
    @echo "âœ“ Environment ready! Activate with: source .venv/bin/activate"

# Setup CPU-only environment (no CUDA)
setup-cpu:
    @echo "ğŸ“¦ Setting up nuPlan (CPU-only)..."
    uv sync --extra torch-cpu --extra dev --extra tutorials
    @echo "âœ“ CPU environment ready!"

# Install just the core dependencies (no dev tools)
install:
    @echo "ğŸ“¦ Installing nuPlan core dependencies..."
    uv sync --extra torch-cuda11
    @echo "âœ“ Core installation complete!"

# Update all dependencies to latest compatible versions
update:
    @echo "ğŸ”„ Updating dependencies..."
    uv lock --upgrade
    uv sync
    @echo "âœ“ Dependencies updated!"

# Run Jupyter Lab for tutorials
tutorial:
    @echo "ğŸ“ Launching Jupyter Lab for nuPlan tutorials..."
    uv run jupyter lab tutorials/

# Run specific tutorial notebook
notebook name:
    @echo "ğŸ“ Opening tutorial: {{name}}"
    uv run jupyter lab tutorials/{{name}}.ipynb

# Run all tests
test:
    @echo "ğŸ§ª Running test suite..."
    uv run pytest -v

# Run tests with coverage
test-coverage:
    @echo "ğŸ§ª Running tests with coverage..."
    uv run pytest --cov=nuplan --cov-report=html --cov-report=term
    @echo "ğŸ“Š Coverage report: htmlcov/index.html"

# Run specific test file or directory
test-path path:
    @echo "ğŸ§ª Running tests in: {{path}}"
    uv run pytest {{path}} -v

# Lint code with all pre-commit hooks
lint:
    @echo "ğŸ” Running linters..."
    uv run pre-commit run --all-files --hook-stage manual

# Format code with black and isort
format:
    @echo "âœ¨ Formatting code..."
    uv run black nuplan tutorials --line-length=120 --skip-string-normalization
    uv run isort nuplan tutorials --line-length=120 --profile=black
    @echo "âœ“ Code formatted!"

# Type check with mypy
typecheck:
    @echo "ğŸ” Type checking..."
    uv run mypy nuplan --config-file=.mypy.ini --ignore-missing-imports

# Run nuplan CLI command
cli *args:
    uv run nuplan_cli {{args}}

# Build Docker image with uv
docker-build:
    @echo "ğŸ³ Building Docker image..."
    docker build -t nuplan-devkit:latest .
    @echo "âœ“ Docker image built!"

# Run Docker container
docker-run:
    @echo "ğŸ³ Starting Docker container..."
    docker-compose up

# Clean generated files and caches
clean:
    @echo "ğŸ§¹ Cleaning build artifacts..."
    rm -rf build/ dist/ *.egg-info .pytest_cache/ .coverage htmlcov/
    find . -type d -name __pycache__ -exec rm -rf {} +
    find . -type f -name "*.pyc" -delete
    @echo "âœ“ Clean complete!"

# Deep clean including uv cache and venv
clean-all: clean
    @echo "ğŸ§¹ Deep cleaning (including venv)..."
    rm -rf .venv/
    uv cache clean
    @echo "âœ“ Deep clean complete!"

# Show environment info
info:
    @echo "ğŸ“Š nuPlan Environment Info:"
    @echo "----------------------------"
    @echo "Python version:"
    @uv run python --version
    @echo "\nPyTorch version:"
    @uv run python -c "import torch; print(f'  {torch.__version__}')" 2>/dev/null || echo "  Not installed"
    @echo "\nCUDA available:"
    @uv run python -c "import torch; print(f'  {torch.cuda.is_available()}')" 2>/dev/null || echo "  N/A"
    @echo "\nCUDA devices:"
    @uv run python -c "import torch; print(f'  {torch.cuda.device_count()} device(s)')" 2>/dev/null || echo "  N/A"
    @echo "\nEnvironment variables:"
    @env | grep NUPLAN || echo "  No NUPLAN_* vars set"
    @echo "\nuv version:"
    @uv --version

# Check CUDA setup
check-cuda:
    @echo "ğŸ” Checking CUDA setup..."
    @uv run python -c "import torch; print(f'PyTorch: {torch.__version__}'); print(f'CUDA Available: {torch.cuda.is_available()}'); print(f'CUDA Version: {torch.version.cuda}' if torch.cuda.is_available() else 'No CUDA'); print(f'Device Count: {torch.cuda.device_count()}'); [print(f'Device {i}: {torch.cuda.get_device_name(i)}') for i in range(torch.cuda.device_count())]"

# Install pre-commit hooks
install-hooks:
    @echo "ğŸª Installing pre-commit hooks..."
    uv run pre-commit install
    @echo "âœ“ Pre-commit hooks installed!"

# Download nuPlan datasets (unified flexible command)
# Examples:
#   just download --all-db              # All database files (test, val, train)
#   just download --test --val          # Specific datasets
#   just download --interactive         # Interactive mode
#   just download --all-db --extract    # Download and extract
download *args:
    @echo "ğŸ“¥ nuPlan Dataset Download Manager"
    @echo "âš ï¸  Ensure NUPLAN_DATA_ROOT is set in your environment"
    uv run nuplan_cli download datasets {{args}}

# Set up environment variables template
setup-env:
    @if [ ! -f .env ]; then \
        cp .env.example .env; \
        echo "ğŸ“ Created .env file - please edit with your paths"; \
    else \
        echo "âš ï¸  .env already exists, not overwriting"; \
    fi

# Quick smoke test - verify installation works
smoke-test:
    @echo "ğŸ’¨ Running smoke test..."
    @uv run python -c "import nuplan; print('âœ“ nuPlan imports successfully')"
    @uv run python -c "import torch; assert torch.cuda.is_available(), 'CUDA not available!'; print('âœ“ CUDA is available')"
    @echo "âœ“ Smoke test passed!"

# Comprehensive health check of the environment
health:
    @echo "ğŸ¥ Running comprehensive health check..."
    uv run python scripts/health_check.py

# Show dataset statistics (if dataset is available)
dataset-info:
    @echo "ğŸ“Š Dataset Information:"
    @uv run python -c "import os; root=os.getenv('NUPLAN_DATA_ROOT', 'Not set'); print(f'NUPLAN_DATA_ROOT: {root}')"
    @uv run python -c "import os; root=os.getenv('NUPLAN_MAPS_ROOT', 'Not set'); print(f'NUPLAN_MAPS_ROOT: {root}')"
    @uv run python -c "import os; root=os.getenv('NUPLAN_EXP_ROOT', 'Not set'); print(f'NUPLAN_EXP_ROOT: {root}')"

# Explore full nuPlan dataset structure (all train/val/test splits)
explore:
    @echo "ğŸ” Exploring nuPlan dataset structure..."
    uv run nuplan_cli explore datasets

# Explore sensor blob zips available in S3 (scrape actual file list)
explore-sensors set="mini":
    @echo "ğŸ” Exploring sensor blob zips for {{set}}_set..."
    uv run nuplan_cli explore sensors --sensor-set={{set}}

# Show dataset inventory (local vs remote)
inventory *args:
    @echo "ğŸ“¦ Dataset Inventory:"
    uv run nuplan_cli inventory main {{args}}

# Show which logs have sensor blobs
inventory-logs *args:
    @echo "ğŸ“¦ Sensor Blob Status:"
    uv run nuplan_cli inventory logs {{args}}

# Map log or DB file to required sensor blob zips
map-log log_name:
    @echo "ğŸ—ºï¸  Mapping log to sensor blob zips:"
    uv run nuplan_cli map log {{log_name}}

# Map DB files to required sensor blob zips
map-db *db_files:
    @echo "ğŸ—ºï¸  Mapping DB files to sensor blob zips:"
    uv run nuplan_cli map db {{db_files}}

# Download tutorial setup (mini dataset + camera_0 + lidar_0)
download-tutorial:
    @echo "ğŸ“¥ Generating download commands for tutorial setup..."
    @echo "   (mini DB + camera_0 + lidar_0 = ~418 GB)"
    uv run nuplan_cli download datasets --mini --camera=0 --lidar=0

# Download all database files (no sensors) - what most researchers need
download-db:
    @echo "ğŸ“¥ Generating download commands for all database files..."
    @echo "   (test + val + all train splits, no sensors)"
    uv run nuplan_cli download datasets --all-db

# Interactive download mode - shows table and prompts for selection
download-interactive:
    @echo "ğŸ“¥ Starting interactive download mode..."
    uv run nuplan_cli download datasets --interactive

# Interactive Python shell with nuPlan loaded
shell:
    @echo "ğŸ Starting Python shell with nuPlan..."
    uv run ipython

# Generate documentation
docs:
    @echo "ğŸ“š Generating documentation..."
    cd docs && uv run make html
    @echo "ğŸ“– Docs: docs/_build/html/index.html"

# Serve documentation locally
docs-serve:
    @echo "ğŸ“š Serving documentation at http://localhost:8000"
    cd docs/_build/html && python -m http.server 8000

# Train a raster model (full tutorial training)
train:
    @echo "ğŸš— Training raster model (10 epochs, 500 scenarios)..."
    @echo "   Output: $${NUPLAN_EXP_ROOT:-$$HOME/nuplan/exp}/tutorial_nuplan_framework/training_raster_experiment/"
    @echo "   Monitor: tail -f $${NUPLAN_EXP_ROOT:-$$HOME/nuplan/exp}/tutorial_nuplan_framework/training_raster_experiment/train_default_raster/*/log.txt"
    uv run python nuplan/planning/script/run_training.py \
        group=$${NUPLAN_EXP_ROOT:-$$HOME/nuplan/exp}/tutorial_nuplan_framework \
        cache.cache_path=$${NUPLAN_EXP_ROOT:-$$HOME/nuplan/exp}/cache \
        experiment_name=training_raster_experiment \
        job_name=train_default_raster \
        py_func=train \
        +training=training_raster_model \
        scenario_builder=nuplan_mini \
        scenario_filter.limit_total_scenarios=500 \
        lightning.trainer.params.accelerator=ddp \
        lightning.trainer.params.max_epochs=10 \
        data_loader.params.batch_size=8 \
        data_loader.params.num_workers=8

# Quick training run (reduced epochs/scenarios for testing)
train-quick:
    @echo "ğŸš— Quick training (3 epochs, 100 scenarios)..."
    uv run python nuplan/planning/script/run_training.py \
        group=$${NUPLAN_EXP_ROOT:-$$HOME/nuplan/exp}/tutorial_nuplan_framework \
        cache.cache_path=$${NUPLAN_EXP_ROOT:-$$HOME/nuplan/exp}/cache \
        experiment_name=training_raster_quick \
        job_name=train_quick \
        py_func=train \
        +training=training_raster_model \
        scenario_builder=nuplan_mini \
        scenario_filter.limit_total_scenarios=100 \
        lightning.trainer.params.accelerator=ddp \
        lightning.trainer.params.max_epochs=3 \
        data_loader.params.batch_size=8 \
        data_loader.params.num_workers=8

# Run simulation with simple planner
simulate:
    @echo "ğŸ® Running simulation with simple planner..."
    uv run python nuplan/planning/script/run_simulation.py \
        experiment_name=simulation_simple_experiment \
        group=$${NUPLAN_EXP_ROOT:-$$HOME/nuplan/exp}/tutorial_nuplan_framework \
        planner=simple_planner \
        +simulation=open_loop_boxes \
        scenario_builder=nuplan_mini \
        scenario_filter=all_scenarios \
        scenario_filter.scenario_types=[near_multiple_vehicles,on_pickup_dropoff,starting_unprotected_cross_turn,high_magnitude_jerk] \
        scenario_filter.num_scenarios_per_type=10

# Run simulation with trained ML planner (auto-detects latest checkpoint if not specified)
simulate-ml checkpoint="":
    #!/usr/bin/env bash
    set -euo pipefail

    EXP_ROOT="${NUPLAN_EXP_ROOT:-$HOME/nuplan/exp}"

    if [ -z "{{checkpoint}}" ]; then
        echo "ğŸ” No checkpoint specified, finding most recent..."
        CHECKPOINT=`find "$EXP_ROOT/tutorial_nuplan_framework/training_raster_experiment" -name "*.ckpt" -type f 2>/dev/null | xargs ls -t 2>/dev/null | head -1`
        if [ -z "$CHECKPOINT" ]; then
            echo "âŒ No checkpoints found in $EXP_ROOT/tutorial_nuplan_framework/training_raster_experiment/"
            echo "   Run 'just train' first to create a checkpoint"
            exit 1
        fi
        echo "   Using: $CHECKPOINT"
    else
        CHECKPOINT="{{checkpoint}}"
        echo "ğŸ® Running simulation with ML planner..."
        echo "   Using checkpoint: $CHECKPOINT"
    fi

    # AIDEV-NOTE: Use direct python instead of uv run to avoid Ray uv integration issues
    # Ray's uv integration creates minimal venvs without extras like torch-cuda11
    .venv/bin/python nuplan/planning/script/run_simulation.py \
        experiment_name=simulation_raster_experiment \
        group="$EXP_ROOT/tutorial_nuplan_framework" \
        planner=ml_planner \
        model=raster_model \
        planner.ml_planner.model_config=\${model} \
        planner.ml_planner.checkpoint_path="$CHECKPOINT" \
        +simulation=open_loop_boxes \
        scenario_builder=nuplan_mini \
        scenario_filter=all_scenarios \
        scenario_filter.scenario_types=[near_multiple_vehicles,on_pickup_dropoff,starting_unprotected_cross_turn,high_magnitude_jerk] \
        scenario_filter.num_scenarios_per_type=10 \
        worker.threads_per_node=4

# Launch nuBoard visualization dashboard
nuboard *paths:
    @echo "ğŸ“Š Launching nuBoard dashboard..."
    @if [ -z "{{paths}}" ]; then \
        echo "   No simulation paths provided - you can load them in the UI"; \
        uv run python nuplan/planning/script/run_nuboard.py scenario_builder=nuplan_mini; \
    else \
        echo "   Loading: {{paths}}"; \
        uv run python nuplan/planning/script/run_nuboard.py scenario_builder=nuplan_mini simulation_path='[{{paths}}]'; \
    fi

# Monitor training progress (follows log file)
train-monitor:
    @echo "ğŸ‘€ Monitoring training logs..."
    @EXP_ROOT="$${NUPLAN_EXP_ROOT:-$$HOME/nuplan/exp}"; \
    LOG_FILE=$$(ls -t "$$EXP_ROOT/tutorial_nuplan_framework/training_raster_experiment/train_*/*/log.txt" 2>/dev/null | head -1); \
    if [ -z "$$LOG_FILE" ]; then \
        echo "âŒ No training logs found in $$EXP_ROOT/tutorial_nuplan_framework/training_raster_experiment/"; \
        exit 1; \
    else \
        echo "   Following: $$LOG_FILE"; \
        tail -f "$$LOG_FILE"; \
    fi

# Launch TensorBoard for training visualization
tensorboard:
    @echo "ğŸ“ˆ Launching TensorBoard..."
    @EXP_ROOT="$${NUPLAN_EXP_ROOT:-$$HOME/nuplan/exp}"; \
    LATEST_RUN=$$(ls -td "$$EXP_ROOT/tutorial_nuplan_framework/training_raster_experiment/train_default_raster/"*/ 2>/dev/null | head -1); \
    if [ -z "$$LATEST_RUN" ]; then \
        echo "âŒ No training runs found"; \
        exit 1; \
    else \
        echo "   Viewing: $$LATEST_RUN"; \
        echo "   URL: http://localhost:6010"; \
        uv run tensorboard --logdir "$$LATEST_RUN" --port 6010; \
    fi

# List available model checkpoints
checkpoints:
    #!/usr/bin/env bash
    echo "ğŸ“¦ Available model checkpoints:"
    EXP_ROOT="${NUPLAN_EXP_ROOT:-$HOME/nuplan/exp}"
    find "$EXP_ROOT/tutorial_nuplan_framework/training_raster_experiment" -name "*.ckpt" -type f 2>/dev/null | \
        while read ckpt; do \
            size=$(du -h "$ckpt" | cut -f1); \
            echo "   [$size] $ckpt"; \
        done || echo "   No checkpoints found"

# Clean up temp directories (Ray sessions, stale cache)
clean-tmp:
    @echo "ğŸ§¹ Cleaning up temp directories..."
    @EXP_ROOT="$${NUPLAN_EXP_ROOT:-$$HOME/nuplan/exp}"; \
    echo "ğŸ“Š Before cleanup:"; \
    du -sh ~/.tmp 2>/dev/null || echo "   ~/.tmp: not found"; \
    du -sh /tmp/ray 2>/dev/null || echo "   /tmp/ray: not found"; \
    du -sh "$$EXP_ROOT/cache" 2>/dev/null || echo "   $$EXP_ROOT/cache: not found"; \
    echo ""; \
    echo "ğŸ—‘ï¸  Removing Ray sessions..."; \
    rm -rf ~/.tmp/ray/session-* 2>/dev/null || true; \
    rm -rf /tmp/ray/session-* 2>/dev/null || true; \
    echo "ğŸ—‘ï¸  Removing old nuPlan cache (>30 days)..."; \
    find "$$EXP_ROOT/cache" -mtime +30 -type f -delete 2>/dev/null || true; \
    echo ""; \
    echo "ğŸ“Š After cleanup:"; \
    du -sh ~/.tmp 2>/dev/null || echo "   ~/.tmp: not found"; \
    du -sh /tmp/ray 2>/dev/null || echo "   /tmp/ray: not found"; \
    du -sh "$$EXP_ROOT/cache" 2>/dev/null || echo "   $$EXP_ROOT/cache: not found"; \
    echo "âœ“ Cleanup complete!"

# ============================================================
# Real-Time Visualization (Phase 1: Streaming Callback)
# ============================================================

# Test streaming visualization callback (without WebSocket server)
test-streaming-callback:
    #!/usr/bin/env bash
    set -euo pipefail
    echo "ğŸ¬ Testing streaming visualization callback (no WebSocket server)..."
    echo "   Expected: Simulation runs successfully, logs WebSocket connection warnings"
    echo ""
    EXP_ROOT="${NUPLAN_EXP_ROOT:-$HOME/nuplan/exp}"
    .venv/bin/python nuplan/planning/script/run_simulation.py \
        experiment_name=test_streaming_viz \
        group="$EXP_ROOT/test" \
        planner=simple_planner \
        +simulation=open_loop_boxes \
        scenario_builder=nuplan_mini \
        scenario_filter=one_of_each_scenario_type \
        scenario_filter.num_scenarios_per_type=1 \
        worker=sequential \
        +callback=streaming_viz_callback

# Profile streaming callback overhead (A/B test with 1 scenario)
profile-streaming-overhead:
    #!/usr/bin/env bash
    set -euo pipefail
    echo "â±ï¸  Profiling streaming visualization overhead (1 scenario A/B test)..."
    echo "   Target: < 5% overhead from streaming callback"
    echo ""
    EXP_ROOT="${NUPLAN_EXP_ROOT:-$HOME/nuplan/exp}"

    # Extract just simulation time (ignore 20s scenario loading overhead)
    echo "ğŸ“Š Run 1: Baseline (no streaming callback)"
    BASELINE_START=$(date +%s.%N)
    .venv/bin/python nuplan/planning/script/run_simulation.py \
        experiment_name=profile_baseline \
        group="$EXP_ROOT/profile" \
        planner=simple_planner \
        +simulation=open_loop_boxes \
        scenario_builder=nuplan_mini \
        scenario_filter.scenario_types=[near_multiple_vehicles] \
        scenario_filter.num_scenarios_per_type=1 \
        worker=sequential \
        2>&1 | tee /tmp/profile_baseline.log
    BASELINE_END=$(date +%s.%N)
    BASELINE_DURATION=$(echo "$BASELINE_END - $BASELINE_START" | bc)

    echo ""
    echo "ğŸ“Š Run 2: With streaming callback"
    STREAMING_START=$(date +%s.%N)
    .venv/bin/python nuplan/planning/script/run_simulation.py \
        experiment_name=profile_streaming \
        group="$EXP_ROOT/profile" \
        planner=simple_planner \
        +simulation=open_loop_boxes \
        scenario_builder=nuplan_mini \
        scenario_filter.scenario_types=[near_multiple_vehicles] \
        scenario_filter.num_scenarios_per_type=1 \
        worker=sequential \
        +callback=streaming_viz_callback \
        2>&1 | tee /tmp/profile_streaming.log
    STREAMING_END=$(date +%s.%N)
    STREAMING_DURATION=$(echo "$STREAMING_END - $STREAMING_START" | bc)

    # Calculate overhead
    OVERHEAD=$(echo "scale=2; (($STREAMING_DURATION - $BASELINE_DURATION) / $BASELINE_DURATION) * 100" | bc)

    echo ""
    echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    echo "ğŸ“ˆ Performance Results:"
    echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    echo "   Baseline:  ${BASELINE_DURATION}s"
    echo "   Streaming: ${STREAMING_DURATION}s"
    echo "   Overhead:  ${OVERHEAD}%"
    echo ""
    if (( $(echo "$OVERHEAD < 5" | bc -l) )); then
        echo "âœ… SUCCESS: Overhead < 5% target!"
    else
        echo "âš ï¸  WARNING: Overhead exceeds 5% target"
    fi
    echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"

# Launch WebSocket visualization server (Phase 2)
viz-server:
    @echo "ğŸŒ Launching WebSocket visualization server..."
    @echo "   WebSocket endpoint: ws://localhost:8765/stream"
    @echo "   Health check: http://localhost:8765/"
    @echo ""
    uv run uvicorn nuplan.planning.visualization.ws_server:app --port 8765 --host 0.0.0.0

# Run simulation with live streaming (requires viz-server running)
simulate-live planner="simple_planner":
    @echo "ğŸ¬ Running live simulation with streaming visualization..."
    @echo "   âš ï¸  Make sure WebSocket server is running: just viz-server"
    @echo "   ğŸ“Š Simulating 1 scenario for quick testing"
    @echo ""
    .venv/bin/python nuplan/planning/script/run_simulation.py \
        experiment_name=live_streaming_test \
        planner={{planner}} \
        +simulation=open_loop_boxes \
        scenario_builder=nuplan_mini \
        scenario_filter.scenario_types=[near_multiple_vehicles] \
        scenario_filter.num_scenarios_per_type=1 \
        worker=sequential \
        +callback=streaming_viz_callback

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Web Dashboard Commands (Phase 3)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Install web dashboard dependencies
web-install:
    @echo "ğŸ“¦ Installing web dashboard dependencies..."
    cd web && npm install
    @echo "âœ“ Web dependencies installed!"

# Start web development server
web-dev:
    @echo "ğŸŒ Starting web development server..."
    @echo "   Dashboard: http://localhost:3000"
    @echo "   Auto-reload: enabled"
    @echo ""
    @echo "   âš ï¸  Make sure WebSocket server is running: just viz-server"
    @echo ""
    cd web && npm run dev

# Build web dashboard for production
web-build:
    @echo "ğŸ—ï¸  Building web dashboard for production..."
    cd web && npm run build
    @echo "âœ“ Build complete! Output in web/dist/"

# Preview production build
web-preview:
    @echo "ğŸ‘ï¸  Previewing production build..."
    @echo "   Dashboard: http://localhost:4173"
    cd web && npm run preview

# Run complete visualization stack (server + web)
viz-stack:
    #!/usr/bin/env bash
    set -euo pipefail

    echo "ğŸš€ Starting complete visualization stack..."
    echo ""
    echo "   1. WebSocket Server: ws://localhost:8765/stream"
    echo "   2. Web Dashboard: http://localhost:3000"
    echo ""
    echo "   Press Ctrl+C to stop all services"
    echo ""

    # Check if web dependencies are installed
    if [ ! -d "web/node_modules" ]; then
        echo "ğŸ“¦ Installing web dependencies first..."
        cd web && npm install
    fi

    # Start both servers in background
    trap 'kill $(jobs -p) 2>/dev/null' EXIT

    echo "ğŸŒ Starting WebSocket server..."
    just viz-server &
    sleep 2

    echo "ğŸŒ Starting web dev server..."
    just web-dev &

    # Wait for both processes
    wait

# Run full end-to-end test (server + web + simulation)
viz-test:
    #!/usr/bin/env bash
    set -euo pipefail

    echo "ğŸ§ª Running end-to-end visualization test..."
    echo ""
    echo "   This will:"
    echo "   1. Start WebSocket server"
    echo "   2. Start web dashboard"
    echo "   3. Run 1 test scenario with streaming"
    echo ""

    # Check if web dependencies are installed
    if [ ! -d "web/node_modules" ]; then
        echo "ğŸ“¦ Installing web dependencies first..."
        cd web && npm install
    fi

    # Start servers in background
    trap 'kill $(jobs -p) 2>/dev/null' EXIT

    echo "ğŸŒ Starting WebSocket server..."
    just viz-server > /tmp/viz-server.log 2>&1 &
    sleep 2

    echo "ğŸŒ Starting web dashboard..."
    just web-dev > /tmp/viz-web.log 2>&1 &
    sleep 3

    echo ""
    echo "âœ“ Servers started!"
    echo "   Open browser to: http://localhost:3000"
    echo ""
    echo "ğŸ¬ Running test simulation..."
    echo ""

    # Run simulation with streaming
    just simulate-live simple_planner

    echo ""
    echo "âœ“ Test complete!"
    echo "   Servers are still running - press Ctrl+C to stop"
    wait
