# ABOUTME: Just command runner for common nuPlan development tasks
# ABOUTME: Run `just` or `just --list` to see all available commands

# Default recipe - show help
default:
    @just --list

# Setup full development environment with CUDA support
setup:
    @echo "ğŸ“¦ Setting up nuPlan development environment with CUDA..."
    uv sync --all-extras
    @echo "âœ“ Environment ready! Activate with: source .venv/bin/activate"

# Setup CPU-only environment (no CUDA)
setup-cpu:
    @echo "ğŸ“¦ Setting up nuPlan (CPU-only)..."
    uv sync --extra torch-cpu --extra dev --extra tutorials
    @echo "âœ“ CPU environment ready!"

# Install just the core dependencies (no dev tools)
install:
    @echo "ğŸ“¦ Installing nuPlan core dependencies..."
    uv sync --extra torch-cuda11
    @echo "âœ“ Core installation complete!"

# Update all dependencies to latest compatible versions
update:
    @echo "ğŸ”„ Updating dependencies..."
    uv lock --upgrade
    uv sync
    @echo "âœ“ Dependencies updated!"

# Run Jupyter Lab for tutorials
tutorial:
    @echo "ğŸ“ Launching Jupyter Lab for nuPlan tutorials..."
    uv run jupyter lab tutorials/

# Run specific tutorial notebook
notebook name:
    @echo "ğŸ“ Opening tutorial: {{name}}"
    uv run jupyter lab tutorials/{{name}}.ipynb

# Run all tests
test:
    @echo "ğŸ§ª Running test suite..."
    uv run pytest -v

# Run tests with coverage
test-coverage:
    @echo "ğŸ§ª Running tests with coverage..."
    uv run pytest --cov=nuplan --cov-report=html --cov-report=term
    @echo "ğŸ“Š Coverage report: htmlcov/index.html"

# Run specific test file or directory
test-path path:
    @echo "ğŸ§ª Running tests in: {{path}}"
    uv run pytest {{path}} -v

# Lint code with all pre-commit hooks
lint:
    @echo "ğŸ” Running linters..."
    uv run pre-commit run --all-files --hook-stage manual

# Format code with black and isort
format:
    @echo "âœ¨ Formatting code..."
    uv run black nuplan tutorials --line-length=120 --skip-string-normalization
    uv run isort nuplan tutorials --line-length=120 --profile=black
    @echo "âœ“ Code formatted!"

# Type check with mypy
typecheck:
    @echo "ğŸ” Type checking..."
    uv run mypy nuplan --config-file=.mypy.ini --ignore-missing-imports

# Run nuplan CLI command
cli *args:
    uv run nuplan_cli {{args}}

# Build Docker image with uv
docker-build:
    @echo "ğŸ³ Building Docker image..."
    docker build -t nuplan-devkit:latest .
    @echo "âœ“ Docker image built!"

# Run Docker container
docker-run:
    @echo "ğŸ³ Starting Docker container..."
    docker-compose up

# Clean generated files and caches
clean:
    @echo "ğŸ§¹ Cleaning build artifacts..."
    rm -rf build/ dist/ *.egg-info .pytest_cache/ .coverage htmlcov/
    find . -type d -name __pycache__ -exec rm -rf {} +
    find . -type f -name "*.pyc" -delete
    @echo "âœ“ Clean complete!"

# Deep clean including uv cache and venv
clean-all: clean
    @echo "ğŸ§¹ Deep cleaning (including venv)..."
    rm -rf .venv/
    uv cache clean
    @echo "âœ“ Deep clean complete!"

# Show environment info
info:
    @echo "ğŸ“Š nuPlan Environment Info:"
    @echo "----------------------------"
    @echo "Python version:"
    @uv run python --version
    @echo "\nPyTorch version:"
    @uv run python -c "import torch; print(f'  {torch.__version__}')" 2>/dev/null || echo "  Not installed"
    @echo "\nCUDA available:"
    @uv run python -c "import torch; print(f'  {torch.cuda.is_available()}')" 2>/dev/null || echo "  N/A"
    @echo "\nCUDA devices:"
    @uv run python -c "import torch; print(f'  {torch.cuda.device_count()} device(s)')" 2>/dev/null || echo "  N/A"
    @echo "\nEnvironment variables:"
    @env | grep NUPLAN || echo "  No NUPLAN_* vars set"
    @echo "\nuv version:"
    @uv --version

# Check CUDA setup
check-cuda:
    @echo "ğŸ” Checking CUDA setup..."
    @uv run python -c "import torch; print(f'PyTorch: {torch.__version__}'); print(f'CUDA Available: {torch.cuda.is_available()}'); print(f'CUDA Version: {torch.version.cuda}' if torch.cuda.is_available() else 'No CUDA'); print(f'Device Count: {torch.cuda.device_count()}'); [print(f'Device {i}: {torch.cuda.get_device_name(i)}') for i in range(torch.cuda.device_count())]"

# Install pre-commit hooks
install-hooks:
    @echo "ğŸª Installing pre-commit hooks..."
    uv run pre-commit install
    @echo "âœ“ Pre-commit hooks installed!"

# Download nuPlan dataset (requires credentials)
download-dataset:
    @echo "ğŸ“¥ Downloading nuPlan dataset..."
    @echo "âš ï¸  Ensure NUPLAN_DATA_ROOT is set in your environment"
    uv run nuplan_cli download

# Set up environment variables template
setup-env:
    @if [ ! -f .env ]; then \
        cp .env.example .env; \
        echo "ğŸ“ Created .env file - please edit with your paths"; \
    else \
        echo "âš ï¸  .env already exists, not overwriting"; \
    fi

# Quick smoke test - verify installation works
smoke-test:
    @echo "ğŸ’¨ Running smoke test..."
    @uv run python -c "import nuplan; print('âœ“ nuPlan imports successfully')"
    @uv run python -c "import torch; assert torch.cuda.is_available(), 'CUDA not available!'; print('âœ“ CUDA is available')"
    @echo "âœ“ Smoke test passed!"

# Comprehensive health check of the environment
health:
    @echo "ğŸ¥ Running comprehensive health check..."
    uv run python scripts/health_check.py

# Show dataset statistics (if dataset is available)
dataset-info:
    @echo "ğŸ“Š Dataset Information:"
    @uv run python -c "import os; root=os.getenv('NUPLAN_DATA_ROOT', 'Not set'); print(f'NUPLAN_DATA_ROOT: {root}')"
    @uv run python -c "import os; root=os.getenv('NUPLAN_MAPS_ROOT', 'Not set'); print(f'NUPLAN_MAPS_ROOT: {root}')"
    @uv run python -c "import os; root=os.getenv('NUPLAN_EXP_ROOT', 'Not set'); print(f'NUPLAN_EXP_ROOT: {root}')"

# Interactive Python shell with nuPlan loaded
shell:
    @echo "ğŸ Starting Python shell with nuPlan..."
    uv run ipython

# Generate documentation
docs:
    @echo "ğŸ“š Generating documentation..."
    cd docs && uv run make html
    @echo "ğŸ“– Docs: docs/_build/html/index.html"

# Serve documentation locally
docs-serve:
    @echo "ğŸ“š Serving documentation at http://localhost:8000"
    cd docs/_build/html && python -m http.server 8000
